---
title: "Project 2"
author: "Grace Holliday and Damon D'Ambrosio"
date: "2023-07-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(gbm)
library(randomForest)
```
# Introduction 

The goal/purpose of this project is to explore the factors influencing the 
amount of shares (popularity) of articles published by Mashable in a period of 
two years.

The data includes 39,644 observations of 61 total variables.  For our
exploration, we will use variables num_imgs, num_videos, num_keywords, 
weekday_is variables (including is_weekend), global_subjectivity (Text 
subjectivity),global_sentiment_polarity (Text sentiment polarity), 
global_rate_positive_words (Rate of positive words in the content), 
global_rate_negative_words (Rate of negative words in the content), 
title_subjectivity, and title_polarity, to explore the target variable (shares).

The methods we will use to model the response include:  
- Linear Regression  
- Random Forest  
- Boosted Tree  

# Data
```{r read_in}
dat <- read_csv("OnlineNewsPopularity.csv")

# Subset data to variables we want
dat <- dat[,-c(1:9,12,20:31,39:44, 49:55,58,59)]

# First subsetting to data_channel_is_lifestyle - will automate later.
dattype <- subset(dat,dat$data_channel_is_lifestyle==1)

# Removing data channel columns
dattype <- dattype[,-c(4:9)]
```

# Summarizations  

First, we will produce basic summary statistics and plots about the training 
data. To do this, we first need to divide the data into a training and test 
set.  
```{r data_setup}
# First, establishing every categorical variable as a character
# so can change the factor
dattype$weekday_is_monday <- as.character(dattype$weekday_is_monday)
dattype$weekday_is_tuesday <- as.character(dattype$weekday_is_tuesday)
dattype$weekday_is_wednesday <- as.character(dattype$weekday_is_wednesday)
dattype$weekday_is_thursday <- as.character(dattype$weekday_is_thursday)
dattype$weekday_is_friday <- as.character(dattype$weekday_is_friday)
dattype$weekday_is_saturday <- as.character(dattype$weekday_is_saturday)
dattype$weekday_is_sunday <- as.character(dattype$weekday_is_sunday)

# Creating single variable for day 1 = Monday 2 = Tuesday 3 = Wednesday
# 4 = Thursday 5 = Friday 6 = Saturday 7 = Sunday 0 if no day, also
# making these a factor and not 0 and 1 for ensemble models

for(i in 1:nrow(dattype))
{
  if(dattype[i,4]==1)
  {
    dattype[i,19] <- 'Monday'
    dattype[i,4] <- 'Y'
    dattype[i,5] <- 'N'
    dattype[i,6] <- 'N'
    dattype[i,7] <- 'N'
    dattype[i,8] <- 'N'
    dattype[i,9] <- 'N' 
    dattype[i,10] <- 'N'
  }
  else if (dattype[i,5]==1)
  {
    dattype[i,19] <- 'Tuesday'
    dattype[i,4] <- 'N'
    dattype[i,5] <- 'Y'
    dattype[i,6] <- 'N'
    dattype[i,7] <- 'N'
    dattype[i,8] <- 'N'
    dattype[i,9] <- 'N' 
    dattype[i,10] <- 'N'
  }
  else if (dattype[i,6]==1)
  {
    dattype[i,19] <- 'Wednesday'
    dattype[i,6] <- 'Y'
    dattype[i,4] <- 'N'
    dattype[i,5] <- 'N'
    dattype[i,7] <- 'N'
    dattype[i,8] <- 'N'
    dattype[i,9] <- 'N' 
    dattype[i,10] <- 'N'
  }
  else if (dattype[i,7]==1)
  {
    dattype[i,19] <- 'Thursday'
    dattype[i,6] <- 'N'
    dattype[i,4] <- 'N'
    dattype[i,5] <- 'N'
    dattype[i,7] <- 'Y'
    dattype[i,8] <- 'N'
    dattype[i,9] <- 'N' 
    dattype[i,10] <- 'N'
    }
  else if (dattype[i,8]==1)
  {
    dattype[i,19] <- 'Friday'
    dattype[i,6] <- 'N'
    dattype[i,4] <- 'N'
    dattype[i,5] <- 'N'
    dattype[i,7] <- 'N'
    dattype[i,8] <- 'Y'
    dattype[i,9] <- 'N' 
    dattype[i,10] <- 'N'
  }
  else if (dattype[i,9]==1)
  {
    dattype[i,19] <- 'Saturday'
    dattype[i,6] <- 'N'
    dattype[i,4] <- 'N'
    dattype[i,5] <- 'N'
    dattype[i,7] <- 'N'
    dattype[i,8] <- 'N'
    dattype[i,9] <- 'Y' 
    dattype[i,10] <- 'N'
  }
  else if (dattype[i,10]==1)
  {
    dattype[i,19] <- 'Sunday'
    dattype[i,6] <- 'N'
    dattype[i,4] <- 'N'
    dattype[i,5] <- 'N'
    dattype[i,7] <- 'N'
    dattype[i,8] <- 'N'
    dattype[i,9] <- 'N' 
    dattype[i,10] <- 'Y'
  }
  else
  {
    dattype[i,19] <- 'NA'
  }
}

colnames(dattype)[19] <- 'day'

# and back to a factor
dattype$weekday_is_monday <- as.factor(dattype$weekday_is_monday)
dattype$weekday_is_tuesday <- as.factor(dattype$weekday_is_tuesday)
dattype$weekday_is_wednesday <- as.factor(dattype$weekday_is_wednesday)
dattype$weekday_is_thursday <- as.factor(dattype$weekday_is_thursday)
dattype$weekday_is_friday <- as.factor(dattype$weekday_is_friday)
dattype$weekday_is_saturday <- as.factor(dattype$weekday_is_saturday)
dattype$weekday_is_sunday <- as.factor(dattype$weekday_is_sunday)
dattype$day <- as.factor(dattype$day)

# Setting order of new factor levels
dattype$day <- factor(dattype$day, levels =c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'))

# First setting seed for reproducibility.
set.seed(1234)

# Divide data into training and test set.
train <- sample(1:nrow(dattype), size = nrow(dattype)*.70)
test <- setdiff(1:nrow(dattype), train)

# training and testing subsets
datTrain <- dattype[train, ]
datTest <- dattype[test, ]
```

## Summary Statistics  
Now, we will conduct exploratory data analysis through creation of basic 
summary statistics and graphs exploring variables of interest to our 
response (shares) before we select variables for potential models.

### Mean Shares by Day
```{r summary1}
datTrain %>%
  group_by(day) %>%
  summarise_at(vars(shares), list(name = mean))
```
This summary reveals the average number of shares by day of the week
(Days 1-7, Mon-Sun).  The highest average represents the day with the most
shares.  A day of 0 means no day was specified.

### Total Multimedia (Images and Videos) by Day
```{r summary2}
datTrain %>% group_by(day) %>%
  mutate(total.media = num_imgs + num_videos) %>%
    group_by(day) %>%
      summarize(average = mean(total.media), median = median(total.media), min = min(total.media), max = max(total.media),
                sd =   sd(total.media))
```

This summary provides the mean, median, minimum, maximum, and standard deviation of the total multimedia objects (images + videos) appearing in articles by day. Potential trends in this summary (e.g., if articles published on certain day have more multimedia objects), may indicate some type of collinearity between "day" and the "num_imgs" or "num_videos" variables.

### Insert additional summaries here


## Graphs  

### Number of Images vs Shares
We can inspect the trend of shares as a function of the number of images.  If 
the points show an upward trend, then articles with more images tend to be 
shared more often.  If the points show a downward trend, then articles with 
less images tend to be shared more often.
```{r graph1}
plot(datTrain$shares~datTrain$num_imgs)
```

### Title Subjectivity vs Shares
We can inspect the trend of shares as a function of title subjectivity.  If the 
points show an upward trend, then articles with higher title subjectivity tend
to be shared more often.  If the points show a downward trend, then articles 
with lower title subjectivity tend to be shared more often.
```{r graph2}
plot(datTrain$shares~datTrain$title_subjectivity)
```

### Average Number of Keywords vs Shares
We can inspect the trend of shares as a function of number of keywords.  If the 
bars show an upward trend, then articles with more keywords tend to be shared
more often.  If the bars show a downward trend, then articles with less 
keywords tend to be shared more often.
```{r graph3}
datTrainp2$num_keywords <- as.factor(datTrainp2$num_keywords)
means <- datTrainp2 %>%
  group_by(num_keywords) %>%
  summarise_at(vars(shares), list(name = mean))
barplot(height=means$name, names=means$num_keywords)
```

### Images vs Videos
We can inspect possible relationships between the number of images and videos in an article. If some type of relationship is evident (e.g., articles with more images tend to have more videos), it may suggest some collinearity between these two variables.
```{r graph4, message = FALSE}
g <- ggplot(datTrain, aes(x = scale(num_videos), y = scale(num_imgs)))

g + geom_point() + 
    xlab("Number of videos (standardized)") + ylab("Number of images (standardized)") + 
    geom_smooth() + 
    theme_minimal()
```

### Positive vs negative word rates
We can inspect the relationship between positive and negative word rates in articles. If some type of relationship is evident (e.g., articles with higher positive word rates tend to have lower negative word rates), it may suggest some collinearity between these two variables.

```{r graph5, message = FALSE}
g <- ggplot(datTrain, aes(x = scale(global_rate_positive_words), y = scale(global_rate_negative_words)))

g + geom_point() + 
    xlab("Positive word rate (standardized)") + ylab("Negative word rate (standardized)") + 
    geom_smooth() + 
    theme_minimal()
```

### Title subjectivity by day of week
We can inspect the relationship between title subjectivity and the day of the week to see if certain days tend to have more/less subjective article titles.

```{r graph6, message = FALSE}
g <- ggplot(datTrain, aes(x = day, y = title_subjectivity))

g + geom_bar(stat = "summary", fun = "mean", color = "black", fill = "blue") + 
    xlab("Day") + ylab("Title subjectivity") +
    theme_minimal()
```

### Insert additional graphs here

# Modeling

Linear regression is an analysis method wherein the values of a variable (i.e., response variable) is predicted based upon the value of one more more other variables (i.e., predictor variables). There is an underlying assumption that there is a linear relationship between the response variable and any given predictor. The slope of this line is determined mathematically by minimizing the sum of the squared residuals. 

## Linear Models

This first model will explore the impact of images as combined with number of 
key words, title subjectivity, sentiment polarity, and positive word rate.
```{r lm_1}
mod2 <- lm(shares~num_imgs+num_keywords+title_subjectivity+global_subjectivity+
             global_sentiment_polarity + global_rate_positive_words,
              data=datTrain)
summary(mod2)

###Added section below for automation demonstration###
mod2.demo <- train(shares~num_imgs+num_keywords+title_subjectivity+global_subjectivity+
             global_sentiment_polarity + global_rate_positive_words,
             data = datTrain,
             method = "lm",
             preProcess = c("center", "scale"), 
             trControl = trainControl(method = "cv", number = 5))

#Run on test data
mod2.predict <- predict(mod2.demo, newdata= datTest)

#Obtain RMSE from test set, which will be used in automated comparison
mod2.compare <- postResample(mod2.predict, obs = datTest$shares)
```

The second model explores the impact of videos instead of images. Keywords are retained as a variable. Instead of exploring subjectivity and postive word rates, this model explores the "negative" (i.e., global rate of negative words and maximum polarity of negative words). It also includes an interaction between the number of videos and number of keywords.
```{r lm_2}
#Train model
mod3 <- train(shares ~ num_videos + num_keywords + num_videos:num_keywords + global_rate_negative_words + max_negative_polarity,
              data = datTrain,
              method = "lm",
              preProcess = c("center", "scale"), 
              trControl = trainControl(method = "cv", number = 5))

#Run on test data
mod3.predict <- predict(mod3, newdata = datTest)

#Obtain RMSE from test set, which will be used in automated comparison
mod3.compare <- postResample(mod3.predict, obs = datTest$shares)

```


## Ensemble Models

To streamline model fitting, we will first remove the previously created "day" variable.

```{r remove_days}
# this is regression, not classification
#removing previously created day variable for boosted tree model
datTrain <- datTrain[,-19]
datTest <- datTest[,-19]
```

Now to fit the ensemble models.

### Random Forest Model
Random forests are similar to bagging in the sense that multiple trees (i.e., a "forest") are created from bootstrap samples of data, with the outcome of these trees averaged to form a conclusion. Unlike bagging, not all possible predictors are used in each tree when using a random forest- only a random subset is used for each tree. This in turn makes the trees less correlated with one another, which allows for a greater reduction in variation once the outcomes of all trees are averaged.

Below is a random forest model to predict shares:
```{r random_forest}
#Create model
random.forest.fit <- train(shares ~ ., data = datTrain,
                           method = "rf",
                           preProcess = c("center", "scale"),
                           trControl = trainControl(method = "cv", number = 5),
                           tuneGrid = data.frame(mtry = 1:17))

# plot fit
plot(random.forest.fit)
random.forest.fit$finalModel

# test fit
test_x = datTest[, -18] 
test_y = datTest[, 18] 
pred_y = predict(random.forest.fit, test_x)
x_ax = 1:length(pred_y)
x_ax <- as.numeric(x_ax)
test_y <- test_y$shares 
test_y <- as.integer(test_y)
pred_y <- as.integer(pred_y)
plot(x_ax, test_y, col="blue", pch=20, cex=.9)
lines(x_ax, pred_y, col="red", pch=20, cex=.9)

#Run on test data
random.forest.predict <- predict(random.forest.fit, newdata = datTest)

#Obtain RMSE from test set, which will be used in automated comparison
random.forest.compare <- postResample(random.forest.predict, obs = datTest$shares)
```


### Boosted Tree Model  
Boosting is a general approach that can be applied to trees and allows for the 
slow training of trees.  The trees are grown sequentially with each subsequent 
tree being grown on a modified version of the original data.  The predictions
are then updated as the trees are grown, and new trees are grown by considering
the errors in the trees previously created. Lambda represents a shrinkage
parameter than slows the fitting process.

Below is a boosted tree model to predict shares.
```{r boosted_tree}
boostFit <- train(shares~., data=datTrain, method="gbm",
                      preProcess=c("center","scale"),
                      trControl=trainControl(method='cv',number=5),
                      tuneGrid = expand.grid(n.trees=seq(25,200,50),
                                             interaction.depth=seq(1,4,1),
                                             shrinkage=0.1,
                                             n.minobsinnode=10))

# plot fit
plot(boostFit)
boostFit$finalModel

# test fit
test_x = datTest[, -18] 
test_y = datTest[, 18] 
pred_y = predict(boostFit, test_x)
x_ax = 1:length(pred_y)
x_ax <- as.numeric(x_ax)
test_y <- test_y$shares 
test_y <- as.integer(test_y)
pred_y <- as.integer(pred_y)
plot(x_ax, test_y, col="blue", pch=20, cex=.9)
lines(x_ax, pred_y, col="red", pch=20, cex=.9)

######Below added to demonstrate my concept for automated model comparison######

#Run on test data
boostFit.predict <- predict(boostFit, newdata = datTest)

#Obtain RMSE from test set, which will be used in automated comparison
boostFit.compare <- postResample(boostFit.predict, obs = datTest$shares)
```
Here, the red lines are the predicted values for each observation.  If the red
lines are close to following the blue dots (which are representative of the
actual value for each observation), then the model is closely predicting.


## Comparison

Now, grab all the RMSEs obtained from fitting the 4 models on the test set to determine the "winner."

```{r comparison}
#Compile RMSEs from the 4 models
mod2.RMSE <- mod2.compare[1]
mod3.RMSE <- mod3.compare[1]
random.forest.RMSE <- random.forest.compare[1]
boostFit.RMSE <- boostFit.compare[1]

compare.all <- data.frame(
                    model = c("mod2", "mod3", "random.forest", "boostFit"),
                    RMSE = c(mod2.RMSE, mod3.RMSE, random.forest.RMSE, boostFit.RMSE)
)

winner <- compare.all %>% slice_min(order_by = RMSE)
```

The lowest RMSE obtained on the test set was **`r winner[1,2]`**, which belongs to the **`r winner[1,1]`** model. Therefore, **`r winner[1,1]`** is the winner!

The final standings of all 4 models can be seen below:

```{r final_standings}
compare.all %>% arrange(RMSE) %>% mutate(Final.Rank = rank(RMSE))
```

Automation
Once you’ve completed the above for a particular data channel, adapt the code 
so that you can use a parameter in your build process. You should be able to 
automatically generate an analysis report for each
data_channel_is_* variable - although again, you may want to create a new 
variable to help with the
subsetting. You’ll end up with six total outputted documents.

This should be done by the group member that doesn’t automate the comparison of 
models part.